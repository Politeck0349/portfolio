{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429affa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "url = 'https://pjt3591oo.github.io/'\n",
    "res = req.get(url)\n",
    "soup = bs(res.content, 'lxml')\n",
    "# soup\n",
    "data = soup.select('.p > h3 > a')\n",
    "a = [i.text for i in data]\n",
    "print('\\n'.join(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = soup.select('h4')\n",
    "b = [i.text.strip() for i in data1]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1f73df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = soup.find_all('span','date')\n",
    "c = [i.text[-3:] for i in data2]\n",
    "print(len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a30b83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 2\n",
    "while True:\n",
    "    sub_url = 'page'+str(num)\n",
    "    path = url+sub_url\n",
    "    res = req.get(path)\n",
    "    soup = bs(res.content, 'lxml')\n",
    "    data = soup.select('.p > h3 > a')\n",
    "    data1 = soup.select('h4')\n",
    "    data2 = soup.find_all('span','date')\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        a.append(data[i].text)\n",
    "        b.append(data1[i].text.strip())\n",
    "        cc = data2[i].text\n",
    "        c.append(cc[-3:])\n",
    "\n",
    "    num+=1\n",
    "    if res.status_code!=200:\n",
    "        print('종료',str(res.status_code))\n",
    "        break\n",
    "print(len(a),len(b),len(c))\n",
    "for i in range(len(a)):\n",
    "    print(a[i])\n",
    "    print(b[i])\n",
    "    print(c[i])\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5bd42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mainContent > div > div.box_boxoffice > ol > li:nth-child(3) > div > div.thumb_cont > strong > a\n",
    "#mainContent > div > div.box_boxoffice > ol > li:nth-child(1) > div > div.thumb_cont > strong > a\n",
    "#mainContent > div > div.box_boxoffice > ol > li:nth-child(39) > div > div.thumb_item > div.poster_info > a\n",
    "#mainContent > div > div.box_boxoffice > ol > li:nth-child(5) > div > div.thumb_item > div.poster_movie > img\n",
    "movie_url = 'https://movie.daum.net/ranking/boxoffice/yearly'\n",
    "res = req.get(movie_url)\n",
    "# print(res.status_code)\n",
    "soup = bs(res.content, 'lxml')\n",
    "movie_data = soup.select('.thumb_cont > strong > a')\n",
    "movie_con = soup.select('#mainContent > div > div.box_boxoffice > ol > li')\n",
    "title = []\n",
    "story = []\n",
    "poster = []\n",
    "\n",
    "for i in movie_con:\n",
    "    title.append(i.select_one('div.thumb_cont > strong > a').text)\n",
    "    story.append(i.select_one('.link_story').text.strip())\n",
    "    poster.append(i.select_one('div.poster_movie > img')['src'])\n",
    "\n",
    "#이미지 저장\n",
    "path_down = 'C:/Users/Mac001/Desktop/webc/'\n",
    "if not os.path.isdir(path_down):\n",
    "    os.mkdir(path_down)\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "i = 0\n",
    "for link in poster:\n",
    "    i +=1\n",
    "    urlretrieve(link, path_down + f'{i}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3814412",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in enumerate(['a','b','c']):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e77cb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# from PIL import ImageDraw\n",
    "# im = []\n",
    "# for i in range(len(poster)):\n",
    "#     im.append(Image.open(f'C:/Users/Mac001/Desktop/webc/{i+1}.jpg'))\n",
    "# print(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae739868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "url = 'https://movie.daum.net/ranking/boxoffice/yearly?date=2022'\n",
    "res = req.get(url)\n",
    "soup = bs(res.content, 'lxml')\n",
    "movie = soup.select('#mainContent > div > div.box_boxoffice > ol > li')\n",
    "movie_src = []\n",
    "for idx,m in enumerate(movie):\n",
    "    img_url = m.select_one('div.poster_movie > img')['src']\n",
    "    img_res = req.get(img_url)\n",
    "    \n",
    "    with open('C:/Users/Mac001/Desktop/movie/movie_{}'.format(idx+1), 'wb') as f:\n",
    "        f.write(img_res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee175f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
